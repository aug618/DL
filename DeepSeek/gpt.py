import streamlit as st
from openai import OpenAI
import configparser

# è¯»å–é…ç½®æ–‡ä»¶
config = configparser.ConfigParser()
config.read('config.ini')

# è·å– API å¯†é’¥å’ŒåŸºç¡€ URL
api_key = config['openai']['api_key']
base_url = config['openai']['base_url']

# ä¾§è¾¹æ  UI é…ç½®
with st.sidebar:
    # è®¾ç½®æ ‡é¢˜å’Œå›¾åƒ
    st.markdown(f""" 
    <center>
    <img src="https://i.ibb.co/MgBss0Q/1.webp" alt="1" border="0" width="250" height="220">
    <h1>DeepSeek-V3<sup>ğŸ’¬<sup></h1>
    </center>""", unsafe_allow_html=True)
    
    # ç³»ç»Ÿæ¶ˆæ¯é…ç½®ï¼Œç”¨æˆ·å¯ä»¥è‡ªå®šä¹‰ç³»ç»Ÿæ¶ˆæ¯
    system_message = st.text_area("å®šä¹‰è§’è‰²", value="æˆ‘æ˜¯ç±³å¡”, ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ğŸ¤£")
    
    # åˆ›é€ æ€§è°ƒèŠ‚å™¨ï¼Œè°ƒæ•´ç”Ÿæˆå†…å®¹çš„åˆ›æ„æ€§
    temperature = st.slider("Creativity", min_value=0.0, max_value=2.0, value=1.0, step=0.1,
                            help="The higher the value, the more creative the text will be.")
    
# ä¸»ç•Œé¢è®¾ç½®
st.title("ğŸ¦œç±³å¡”åŠ©æ‰‹")

# ä½¿ç”¨ session_state åˆå§‹åŒ–èŠå¤©è®°å½•
if "chat_history" not in st.session_state:
    st.session_state.chat_history = [{
        "role": "assistant",
        "content": "æˆ‘æ˜¯ç±³å¡”, ä½ å¯ä»¥é—®æˆ‘ä»»ä½•é—®é¢˜ğŸ¤£"
    }]

# æ˜¾ç¤ºèŠå¤©è®°å½•
for message in st.session_state.chat_history:
    with st.chat_message(message["role"]):
        st.markdown(message["content"]) 

# openai å®¢æˆ·ç«¯åˆå§‹åŒ–
client = OpenAI(api_key=api_key, base_url=base_url)
if "messageHistory" not in st.session_state:
    st.session_state.messageHistory = []

# å®šä¹‰èŠå¤©æµå¤„ç†å‡½æ•°
def chat_stream(query, system_message=None, temperature=0.5):
    if system_message:
        st.session_state.messageHistory.append({"role": "system", "content": system_message})
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²è®°å½•
    st.session_state.messageHistory.append({"role": "user", "content": query})

    # è°ƒç”¨ DeepSeek API è·å–èŠå¤©æµæ•°æ®
    response = client.chat.completions.create(
        model="deepseek-chat", 
        messages=st.session_state.messageHistory, 
        stream=True, 
        temperature=temperature
    )
    return response

# å¤„ç†ç”¨æˆ·è¾“å…¥å¹¶æ˜¾ç¤º
user_input = st.chat_input("ä½ æƒ³é—®æˆ‘ä»€ä¹ˆé—®é¢˜?", key="user_input")
if user_input:
    # æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
    with st.chat_message("user"):
        st.write(user_input)

    # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°èŠå¤©å†å²è®°å½•
    st.session_state.chat_history.append({"role": "user", "content": user_input})

    # æ˜¾ç¤ºåŠ è½½çŠ¶æ€å¹¶è°ƒç”¨ DeepSeek æ¥å£
    with st.spinner("è®©æˆ‘æƒ³ä¸€æƒ³å…ˆ..."):
        response = chat_stream(user_input, system_message, temperature)
        message_placeholder = st.empty()
        full_response = ""

        # æŒ‰æµå¼æ•°æ®è·å–å†…å®¹å¹¶æ›´æ–°æ˜¾ç¤º
        for chunk in response:
            if chunk.choices and chunk.choices[0].delta.content:
                full_response += chunk.choices[0].delta.content
                message_placeholder.markdown(full_response + "...")

        # å®Œæˆæ‰€æœ‰å†…å®¹åæ˜¾ç¤ºæœ€ç»ˆå›ç­”
        message_placeholder.markdown(full_response)

        # å°† AI å“åº”æ·»åŠ åˆ°èŠå¤©å†å²è®°å½•
        st.session_state.chat_history.append({"role": "assistant", "content": full_response})
